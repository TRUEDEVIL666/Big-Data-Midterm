{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zQx8cAMubCV"
   },
   "source": [
    "# **PCY Algorithm (PySpark)**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xwoRDKZWuUcP",
    "ExecuteTime": {
     "end_time": "2025-04-05T18:38:39.637685Z",
     "start_time": "2025-04-05T18:38:39.351517Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, collect_set\n",
    "from itertools import combinations\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IhmdHdKfu-hB",
    "ExecuteTime": {
     "end_time": "2025-04-05T18:38:39.669224Z",
     "start_time": "2025-04-05T18:38:39.652973Z"
    }
   },
   "source": [
    "# PCY Algorithm Class\n",
    "class PCYAlgorithm:\n",
    "    def __init__(self, support_threshold, confidence_threshold, num_buckets=100):\n",
    "        \"\"\"\n",
    "        Initialize the PCY Algorithm with user-defined thresholds.\n",
    "\n",
    "        :param support_threshold: Minimum support count to consider an item/pair frequent.\n",
    "        :param confidence_threshold: Minimum confidence level for association rules.\n",
    "        :param num_buckets: Number of hash buckets for pair counting.\n",
    "        \"\"\"\n",
    "        self.support_threshold = support_threshold\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.num_buckets = num_buckets\n",
    "        self.bucket_counts = defaultdict(int)  # Dictionary to store bucket counts\n",
    "\n",
    "    def hash_pair(self, pair):\n",
    "        \"\"\"\n",
    "        Hash function to map item pairs into buckets.\n",
    "\n",
    "        :param pair: A tuple representing an item pair (item1, item2).\n",
    "        :return: A hash bucket index.\n",
    "        \"\"\"\n",
    "        return hash(pair) % self.num_buckets\n",
    "\n",
    "    def count_frequent_items(self, baskets):\n",
    "        \"\"\"\n",
    "        First pass of the PCY algorithm: Count individual items.\n",
    "\n",
    "        :param baskets: List of baskets (transactions), where each basket is a set of items.\n",
    "        :return: Dictionary of frequent items sorted in descending order of count.\n",
    "        \"\"\"\n",
    "        item_counts = defaultdict(int)\n",
    "\n",
    "        # Count occurrences of each item in all baskets\n",
    "        for basket in baskets:\n",
    "            for item in basket:\n",
    "                item_counts[item] += 1\n",
    "\n",
    "        # Sort items by frequency in descending order and return\n",
    "        return dict(sorted(item_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    def count_frequent_pairs(self, baskets, frequent_items):\n",
    "        \"\"\"\n",
    "        Second pass of the PCY algorithm: Count item pairs.\n",
    "\n",
    "        :param baskets: List of baskets (transactions).\n",
    "        :param frequent_items: Dictionary of frequent items from the first pass.\n",
    "        :return: Dictionary of frequent pairs sorted in descending order of count.\n",
    "        \"\"\"\n",
    "        pair_counts = defaultdict(int)\n",
    "\n",
    "        # Iterate through each basket\n",
    "        for basket in baskets:\n",
    "            # Keep only frequent items in the basket\n",
    "            valid_items = [item for item in basket if item in frequent_items]\n",
    "\n",
    "            # Generate all possible item pairs\n",
    "            for pair in combinations(valid_items, 2):\n",
    "                pair_counts[pair] += 1  # Increment pair count\n",
    "                self.bucket_counts[self.hash_pair(pair)] += 1  # Hash pair into a bucket\n",
    "\n",
    "        # Sort pairs by frequency in descending order and return\n",
    "        return dict(sorted(pair_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    def generate_association_rules(self, frequent_pairs, frequent_items):\n",
    "        \"\"\"\n",
    "        Generate association rules based on confidence.\n",
    "\n",
    "        :param frequent_pairs: Dictionary of frequent item pairs.\n",
    "        :param frequent_items: Dictionary of frequent single items.\n",
    "        :return: List of association rules (item1 -> item2) with confidence.\n",
    "        \"\"\"\n",
    "        rules = []\n",
    "\n",
    "        # Compute confidence for each frequent pair\n",
    "        for (item1, item2), count in frequent_pairs.items():\n",
    "            confidence1 = count / frequent_items[item1]  # P(Item2 | Item1)\n",
    "            confidence2 = count / frequent_items[item2]  # P(Item1 | Item2)\n",
    "\n",
    "            # Add rules if confidence meets the threshold\n",
    "            if confidence1 >= self.confidence_threshold:\n",
    "                rules.append((item1, item2, confidence1))\n",
    "            if confidence2 >= self.confidence_threshold:\n",
    "                rules.append((item2, item1, confidence2))\n",
    "\n",
    "        # Sort rules by confidence in descending order and return\n",
    "        return sorted(rules, key=lambda x: x[2], reverse=True)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1gW9SOnkvm6q",
    "ExecuteTime": {
     "end_time": "2025-04-05T18:38:39.692136Z",
     "start_time": "2025-04-05T18:38:39.682792Z"
    }
   },
   "source": [
    "# Function to load and preprocess data from CSV\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load transaction data from baskets.csv and format it into a list of baskets.\n",
    "\n",
    "    :return: List of baskets (each basket is a set of items).\n",
    "    \"\"\"\n",
    "    # Start a Spark session\n",
    "    spark = SparkSession.builder.appName(\"PCYAlgorithm\").getOrCreate()\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = spark.read.csv(\"baskets.csv\", header=True, inferSchema=True)\n",
    "\n",
    "    # Group data by Member_number and Date, aggregating items into a list\n",
    "    baskets_df = df.groupBy(\"Member_number\", \"Date\").agg(collect_set(\"itemDescription\").alias(\"basket\"))\n",
    "\n",
    "    # Convert Spark DataFrame to a list of baskets\n",
    "    baskets = [row[\"basket\"] for row in baskets_df.collect()]\n",
    "\n",
    "    # Stop Spark session\n",
    "    spark.stop()\n",
    "\n",
    "    return baskets\n",
    "\n",
    "# Function to execute the PCY algorithm\n",
    "def run_pcy_algorithm(baskets, support_threshold, confidence_threshold):\n",
    "    \"\"\"\n",
    "    Run the PCY Algorithm on the given transaction baskets.\n",
    "\n",
    "    :param baskets: List of baskets (transactions).\n",
    "    :param support_threshold: Minimum support threshold for frequent items and pairs.\n",
    "    :param confidence_threshold: Minimum confidence threshold for association rules.\n",
    "    :return: Frequent items, frequent pairs, and association rules.\n",
    "    \"\"\"\n",
    "    # Create an instance of the PCYAlgorithm\n",
    "    pcy = PCYAlgorithm(support_threshold, confidence_threshold)\n",
    "\n",
    "    # First pass: Count frequent individual items\n",
    "    frequent_items = pcy.count_frequent_items(baskets)\n",
    "\n",
    "    # Second pass: Count frequent item pairs\n",
    "    frequent_pairs = pcy.count_frequent_pairs(baskets, frequent_items)\n",
    "\n",
    "    # Generate association rules based on confidence\n",
    "    association_rules = pcy.generate_association_rules(frequent_pairs, frequent_items)\n",
    "\n",
    "    return frequent_items, frequent_pairs, association_rules\n",
    "\n",
    "# Function to display results\n",
    "def display_results(frequent_items, frequent_pairs, association_rules):\n",
    "    \"\"\"\n",
    "    Display the top 30 frequent items, frequent pairs, and association rules in descending order.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Top 30 Frequent Items ===\")\n",
    "    for item, count in sorted(frequent_items.items(), key=lambda x: x[1], reverse=True)[:30]:\n",
    "        print(f\"Item: {item}, Count: {count}\")\n",
    "\n",
    "    print(\"\\n=== Top 30 Frequent Pairs ===\")\n",
    "    for pair, count in sorted(frequent_pairs.items(), key=lambda x: x[1], reverse=True)[:30]:\n",
    "        print(f\"Pair: {pair}, Count: {count}\")\n",
    "\n",
    "    print(\"\\n=== Top 30 Association Rules (Sorted by Confidence) ===\")\n",
    "    for item1, item2, confidence in sorted(association_rules, key=lambda x: x[2], reverse=True)[:30]:\n",
    "        print(f\"{item1} -> {item2} (Confidence: {confidence:.2f})\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DJb1U0pBvoW0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e0b5c624-c1ce-4dfd-f375-a4bf3abaa9bf",
    "ExecuteTime": {
     "end_time": "2025-04-05T18:39:16.147053Z",
     "start_time": "2025-04-05T18:38:40.387836Z"
    }
   },
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Load transaction data\n",
    "    baskets = load_data()\n",
    "\n",
    "    # Step 2: Set thresholds and run the PCY Algorithm\n",
    "    support_threshold = 2  # Minimum count for items to be considered frequent\n",
    "    confidence_threshold = 0.5  # Minimum confidence for association rules\n",
    "    frequent_items, frequent_pairs, association_rules = run_pcy_algorithm(baskets, support_threshold, confidence_threshold)\n",
    "\n",
    "    # Step 3: Display results\n",
    "    display_results(frequent_items, frequent_pairs, association_rules)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 30 Frequent Items ===\n",
      "Item: whole milk, Count: 2363\n",
      "Item: other vegetables, Count: 1827\n",
      "Item: rolls/buns, Count: 1646\n",
      "Item: soda, Count: 1453\n",
      "Item: yogurt, Count: 1285\n",
      "Item: root vegetables, Count: 1041\n",
      "Item: tropical fruit, Count: 1014\n",
      "Item: bottled water, Count: 908\n",
      "Item: sausage, Count: 903\n",
      "Item: citrus fruit, Count: 795\n",
      "Item: pastry, Count: 774\n",
      "Item: pip fruit, Count: 734\n",
      "Item: shopping bags, Count: 712\n",
      "Item: canned beer, Count: 702\n",
      "Item: bottled beer, Count: 678\n",
      "Item: whipped/sour cream, Count: 654\n",
      "Item: newspapers, Count: 582\n",
      "Item: frankfurter, Count: 565\n",
      "Item: brown bread, Count: 563\n",
      "Item: domestic eggs, Count: 555\n",
      "Item: pork, Count: 555\n",
      "Item: butter, Count: 527\n",
      "Item: fruit/vegetable juice, Count: 509\n",
      "Item: beef, Count: 508\n",
      "Item: curd, Count: 504\n",
      "Item: margarine, Count: 482\n",
      "Item: coffee, Count: 473\n",
      "Item: frozen vegetables, Count: 419\n",
      "Item: chicken, Count: 417\n",
      "Item: white bread, Count: 359\n",
      "\n",
      "=== Top 30 Frequent Pairs ===\n",
      "Pair: ('whole milk', 'other vegetables'), Count: 222\n",
      "Pair: ('whole milk', 'rolls/buns'), Count: 209\n",
      "Pair: ('whole milk', 'soda'), Count: 174\n",
      "Pair: ('whole milk', 'yogurt'), Count: 167\n",
      "Pair: ('rolls/buns', 'other vegetables'), Count: 158\n",
      "Pair: ('soda', 'other vegetables'), Count: 145\n",
      "Pair: ('whole milk', 'sausage'), Count: 134\n",
      "Pair: ('whole milk', 'tropical fruit'), Count: 123\n",
      "Pair: ('yogurt', 'other vegetables'), Count: 121\n",
      "Pair: ('rolls/buns', 'soda'), Count: 121\n",
      "Pair: ('yogurt', 'rolls/buns'), Count: 117\n",
      "Pair: ('whole milk', 'root vegetables'), Count: 113\n",
      "Pair: ('whole milk', 'bottled beer'), Count: 107\n",
      "Pair: ('whole milk', 'citrus fruit'), Count: 107\n",
      "Pair: ('whole milk', 'bottled water'), Count: 107\n",
      "Pair: ('whole milk', 'pip fruit'), Count: 99\n",
      "Pair: ('pastry', 'whole milk'), Count: 97\n",
      "Pair: ('whole milk', 'shopping bags'), Count: 95\n",
      "Pair: ('tropical fruit', 'other vegetables'), Count: 94\n",
      "Pair: ('rolls/buns', 'tropical fruit'), Count: 91\n",
      "Pair: ('whole milk', 'canned beer'), Count: 90\n",
      "Pair: ('sausage', 'other vegetables'), Count: 90\n",
      "Pair: ('sausage', 'soda'), Count: 89\n",
      "Pair: ('yogurt', 'soda'), Count: 87\n",
      "Pair: ('sausage', 'yogurt'), Count: 86\n",
      "Pair: ('rolls/buns', 'root vegetables'), Count: 85\n",
      "Pair: ('whole milk', 'newspapers'), Count: 84\n",
      "Pair: ('bottled water', 'other vegetables'), Count: 82\n",
      "Pair: ('soda', 'tropical fruit'), Count: 81\n",
      "Pair: ('sausage', 'rolls/buns'), Count: 80\n",
      "\n",
      "=== Top 30 Association Rules (Sorted by Confidence) ===\n",
      "preservation products -> soups (Confidence: 1.00)\n",
      "kitchen utensil -> pasta (Confidence: 1.00)\n",
      "kitchen utensil -> bottled water (Confidence: 1.00)\n",
      "kitchen utensil -> rolls/buns (Confidence: 1.00)\n",
      "bags -> yogurt (Confidence: 0.50)\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

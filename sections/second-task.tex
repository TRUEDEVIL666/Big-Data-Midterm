\subsection{Overview of PCY}
\label{subsec:overview-of-pcy}
Frequent itemsets mining is essential for discovering item associations in transactional data, such as market basket analysis.
The PCY algorithm improves efficiency by using hash buckets to reduce the computational cost of finding frequent item pairs.
This project applies the PCY algorithm to mine frequent itemsets and generate association rules based on support and confidence thresholds, using PySpark for scalable data processing.

The PCY algorithm is based on two key passes through the data.
In the first pass, frequent individual items are identified and counted.
In the second pass, frequent item pairs are counted, and hash buckets are used to prune less frequent pairs.
The hash function maps item pairs to buckets, and only pairs that have a sufficient bucket count are considered frequent.
This approach significantly reduces the number of pair comparisons and improves algorithm efficiency.

\begin{itemize}
    \item Step 1: Count individual items using the support threshold.
    \item Step 2: Count pairs of frequent items and hash them into buckets.
    \item Step 3: Prune item pairs that are not frequent based on the bucket counts.
    \item Step 4: Generate association rules using the confidence threshold.
\end{itemize}

\subsection{Implementation Details}
\label{subsec:implementation-details}

\subsubsection{Data Loading and Preprocessing}
Data is loaded using PySpark’s \texttt{read.csv} function.
Each transaction is represented as a basket, and the data is grouped by customer and date.
The \texttt{collect\_set} function is used to create a list of items bought together in each transaction.

\subsubsection{First Pass: Counting Frequent Items}
In the first pass, each item’s frequency is counted, and only those items that meet the support threshold are considered frequent.
The item counts are stored in a dictionary, sorted in descending order.

\subsubsection{Second Pass: Counting Frequent Pairs}
During the second pass, the algorithm generates pairs from frequent items and counts their occurrences.
Hashing is applied to map pairs into buckets, and the bucket counts are used to prune pairs that do not meet the minimum support threshold.

\subsubsection{Association Rule Generation}
For each frequent pair, confidence is calculated as the ratio of the pair’s count to the individual item count.
Association rules are generated if the confidence meets the given threshold.
The rules are sorted by confidence.

\subsection{Experimental Results}
\label{subsec:experimental-results}
The PCY algorithm was executed on a transactional dataset of retail transactions, where each transaction (basket) represented a set of items purchased by a customer.
The algorithm was applied with the following parameters:
\begin{itemize}
    \item Support threshold: 2 (minimum count for items to be considered frequent).
    \item Confidence threshold: 0.5 (minimum confidence for association rules).
\end{itemize}

\subsubsection{Frequent Items}
The first pass of the algorithm counted the occurrence of each item in the transactions.
The following are the top 30 frequent items identified based on the support threshold:

\begin{table}[h]
    \centering
    \caption{Most Frequent Items with Their Counts}
    \setlength{\tabcolsep}{2pt} % Reduce column spacing
    \renewcommand{\arraystretch}{1} % Adjust row spacing
    \resizebox{120}{!}{ % Fit within column width
        \begin{tabular}{|l|c|}
            \hline
            \textbf{Item} & \textbf{Count} \\
            \hline
            Whole milk & 2363 \\
            Other vegetables & 1827 \\
            Rolls/buns & 1646 \\
            Soda & 1453 \\
            Yogurt & 1285 \\
            Root vegetables & 1041 \\
            Tropical fruit & 1014 \\
            Bottled water & 908 \\
            Sausage & 903 \\
            Citrus fruit & 795 \\
            Pastry & 774 \\
            Pip fruit & 734 \\
            \hline
        \end{tabular}
    }
    \label{tab:frequent_items}
\end{table}

\subsubsection{Frequent Item Pairs}
In the second pass, the algorithm counted pairs of frequent items across all transactions.
The top 30 frequent item pairs, sorted by frequency, are as follows:

\begin{table}[h]
    \centering
    \caption{Frequent Item Pairs with Their Counts}
    \setlength{\tabcolsep}{2pt} % Reduce column spacing
    \renewcommand{\arraystretch}{1} % Adjust row spacing
    \resizebox{160}{!}{ % Fit within column width
        \begin{tabular}{|l|c|}
            \hline
            \textbf{Pair} & \textbf{Count} \\
            \hline
            ('Whole milk', 'Other vegetables') & 222 \\
            ('Whole milk', 'Rolls/buns') & 209 \\
            ('Whole milk', 'Soda') & 174 \\
            ('Whole milk', 'Yogurt') & 167 \\
            ('Rolls/buns', 'Other vegetables') & 158 \\
            ('Soda', 'Other vegetables') & 145 \\
            ('Whole milk', 'Sausage') & 134 \\
            ('Whole milk', 'Tropical fruit') & 123 \\
            ('Yogurt', 'Other vegetables') & 121 \\
            ('Rolls/buns', 'Soda') & 121 \\
            ('Yogurt', 'Rolls/buns') & 117 \\
            ('Whole milk', 'Root vegetables') & 113 \\
            \hline
        \end{tabular}
    }
    \label{tab:frequent_pairs}
\end{table}

\subsubsection{Association Rules}
Once frequent item pairs were identified, association rules were generated based on the confidence threshold of 0.5. The confidence for each rule was computed by dividing the pair count by the count of the antecedent item.
The top 30 association rules, sorted by confidence, are presented below:

\begin{table}[h]
    \centering
    \caption{Validated Association Rules}
    \setlength{\tabcolsep}{2pt} % Reduce column spacing
    \renewcommand{\arraystretch}{1} % Adjust row spacing
    \resizebox{180}{!}{ % Fit within column width
        \begin{tabular}{|l|c|}
            \hline
            \textbf{Rule} & \textbf{Confidence} \\
            \hline
            Preservation products → Soups & 1.00 \\
            Kitchen utensil → Pasta & 1.00 \\
            Kitchen utensil → Bottled water & 1.00 \\
            Kitchen utensil → Rolls/buns & 1.00 \\
            Bags → Yogurt & 0.50 \\
            \hline
        \end{tabular}
    }
    \label{tab:association-rules}
\end{table}

\subsubsection{Performance Evaluation}
The PCY algorithm effectively identified frequent items, pairs, and association rules with reasonable execution time and memory usage.
Given the dataset size, the distributed nature of Spark ensured that the computation was scalable.
\begin{itemize}
    \item Time Complexity: The use of hashing significantly reduces the complexity of item pair generation, making the PCY algorithm faster than traditional algorithms such as the Apriori algorithm.
    \item Memory Usage: Memory usage was managed well by leveraging the distributed processing capabilities of Spark.
\end{itemize}
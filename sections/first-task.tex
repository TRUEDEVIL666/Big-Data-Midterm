\subsection{Overview of A-priori Algorithm}
\label{subsec:overview-of-a-priori-algorithm}

\subsubsection{What is the A-Priori Algorithm}

The A-Priori algorithm is a classic algorithm in data mining used to identify frequent itemsets and derive association rules.
In the context of this project, it is used to discover pairs of customers who frequently shop together.

\begin{itemize}
    \item It is based on the principle that all subsets of a frequent itemset must also be frequent.
    \item It uses a level-wise, breadth-first search approach to count the frequency of itemsets.
    \item It is typically implemented in multiple passes: the first pass finds frequent individual items (1-itemsets), and subsequent passes find larger frequent itemsets (e.g., 2-itemsets, 3-itemsets, etc.).
\end{itemize}

\subsubsection{How the A-Priori Algorithm Works (in this task)}

\begin{itemize}
    \item \textbf{First Pass – Frequent Individual Customers:} Count how many times each individual customer appears in the grouped transaction data.
    Customers with frequency above a defined threshold are considered frequent.
    \item \textbf{Second Pass – Frequent Customer Pairs:} For each transaction (i.e., group of customers on a given date), generate all possible customer pairs where both customers are frequent.
    Count the number of times each pair appears.
    \item \textbf{Support Threshold:} A predefined threshold used to filter out itemsets (customers or pairs) that do not appear frequently enough to be considered relevant.
    \item \textbf{Output:} The algorithm outputs customer pairs that occur together at or above the support threshold.
\end{itemize}

\textbf{Note:} The output of the first subtask (Customer Grouping by Date) will serve as the input for both passes of the second subtask (A-Priori Algorithm):

\begin{itemize}
    \item First Subtask (Customer Grouping by Date):
    \begin{itemize}
        \item \texttt{args[0]} – Input path to the raw transaction CSV file.
        \item \texttt{args[1]} – Output path where grouped customer data by date will be written.
    \end{itemize}

    \item Second Subtask (A-Priori Algorithm):
    \begin{itemize}
        \item \texttt{args[0]} – Input path to the grouped customer data (output from the first subtask).
        \item \texttt{args[1]} – Output path for the first pass (frequent individual customers).
        \item \texttt{args[2]} – Output path for the second pass (frequent customer pairs).
    \end{itemize}
\end{itemize}

This approach allows the workflow to seamlessly transition from the first subtask (grouping by date) to the second subtask (identifying frequent customers and pairs).

\subsection{First subtask}
\label{subsec:first-subtask}

In the first subtask, we are assigned to store the data on HDFS.
After which we will implement a Hadoop MapReduce program in Java to discover groups of customers going shopping at the same date.

\subsubsection{The Mapper Class} \textit{CustomerGroupByDateMapper}

The Mapper class is responsible for reading the input data and emitting key-value pairs.
Key aspects of its implementation include:

\begin{itemize}
    \item Input Processing: The input is a CSV file where each line contains multiple fields, including \texttt{Member\_number} (customer ID) and \texttt{Date} (transaction date).
    \item Filtering Headers: The Mapper skips header lines by checking if the first token equals \texttt{Member\_number}.
    \item Emitting Key-Value Pairs: The key is the transaction date, and the value is the customer ID.
    This allows transactions to be grouped by date in the shuffle and sort phase.
\end{itemize}

Example Output from Mapper:
\begin{center}
(01/01/2014, 11111)\\
(01/01/2014, 22222)\\
(02/01/2014, 11111)
\end{center}

\subsubsection{The Reducer Class} \textit{CustomerGroupByDateReducer}

The Reducer aggregates the values emitted by the Mapper for each unique date.
Key implementation features include:

\begin{itemize}
    \item Collecting Unique Customers: Customer IDs are added to a \texttt{HashSet} to remove duplicates.
    \item Joining Values: The set of unique customer IDs is converted to a comma-separated string.
    \item Emitting Results: The final output consists of the transaction date as the key, and a list of unique customer IDs as the value.
\end{itemize}

Example Output from Reducer:
\begin{center}
(01/01/2014, 11111,22222)\\
(02/01/2014, 11111)
\end{center}

\subsection{Second subtask}
\label{subsec:second-subtask}

In the second subtask, we implement the A-Priori algorithm to identify frequent customer pairs.
This is achieved using two MapReduce passes.

\subsubsection{The First Pass} Identifying Frequent Individual Customers

\begin{itemize}
    \item Mapper Class: \textit{AprioriFirstPassMapper}
    \begin{itemize}
        \item Function: Reads grouped customer data (output of first subtask), splits the customer list, and emits each customer ID with a value of 1.
        \item Input Format: Each line is a tab-separated pair where the key is a date and the value is a comma-separated list of customers.
        \item Filtering: Skips malformed lines where the customer list is missing.
        \item Example Input:
        \begin{center}
            01/01/2014 \tab 12345,67890
        \end{center}
        \item Example Output from Mapper:
        \begin{center}
        (12345, 1)\\
        (67890, 1)
        \end{center}
    \end{itemize}

    \item Reducer Class: \textit{AprioriReducer}
    \begin{itemize}
        \item Function: Aggregates the counts for each key (customer).
        \item Filtering: Emits only \texttt{<key, value>} pairs whose frequency is greater than or equal to the support threshold.
        \item Example Output from Reducer (First Pass):
        \begin{center}
        (12345, 2)\\
        (67890, 1)
        \end{center}
    \end{itemize}
\end{itemize}

\subsubsection{The Second Pass} \textit{Identifying Frequent Customer Pairs}

\begin{itemize}
    \item Mapper Class: \textit{AprioriSecondPassMapper}
    \begin{itemize}
        \item Setup: Loads the list of frequent customers from the first pass output using Hadoop’s distributed cache.
        \item Processing: For each transaction line, splits the list of customer IDs, filters only frequent customers, and generates all valid customer pairs.
        \item Emitting: Outputs each pair of frequent customers with a count of 1.
        \item Example Output from Mapper:
        \begin{center}
        (12345,67890, 1)\\
        (12345,54321, 1)
        \end{center}
    \end{itemize}

    \item Reducer Class: \textit{AprioriReducer}
    \begin{itemize}
        \item The same class as used in the First Pass.
        \item Example Output from Reducer (Second Pass):
        \begin{center}
        (12345,67890, 3)
        \end{center}
    \end{itemize}
\end{itemize}
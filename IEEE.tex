\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{nohyperref}
\newcommand{\BibTeX}{\textrm{B \kern -.05em \textsc{i \kern -.025em b} \kern -.08em
T \kern -.1667em \lower .7ex \hbox{E} \kern -.125emX}}
\begin{document}

    \title{Mining Massive Data Sets Midterm Report}

    \author{
        \IEEEauthorblockN{1\textsuperscript{st} 522H0036 - Luong Canh Phong}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\
            Ho Chi Minh City, Vietnam \\
            522H0036@student.tdtu.edu.com
        }
        \and
        \IEEEauthorblockN{2\textsuperscript{nd} 522H0092 - Cao Nguyen Thai Thuan}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\ \
            Ho Chi Minh City, Vietnam \\
            522H0092@student.tdtu.edu.com
        }
        \and
        \IEEEauthorblockN{3\textsuperscript{rd} 522H0075 - Tang Minh Thien An}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\
            Ho Chi Minh City, Vietnam \\
            522H0075@student.tdtu.edu.com
        }
        \and
        \IEEEauthorblockN{4\textsuperscript{th} 522H0167 - Truong Tri Phong}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\
            Ho Chi Minh City, Vietnam \\
            522H0167@student.tdtu.edu.com
        }
        \and
        \IEEEauthorblockN{5\textsuperscript{th} Instructor: Nguyen Thanh An}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\
            Ho Chi Minh City, Vietnam \\
            nguyenthanhan@tdtu.edu.com
        }
    }

    \maketitle

    \begin{abstract}
        In the age of big data, the ability to mine and extract valuable information from massive datasets can give the user an unparalleled edge against the competition.
        Therefore, this requirement made by the lecturer is designed to simulate one of the three most fundamental challenges in data mining.
        Through these series of tasks, we will explore some algorithm implementations and solve different problems as well as explore their trade-offs.
        Each task is a different algorithm to explore and implement with their corresponding datasets.
        Through these tasks, we will gain some practical insight and experience in working with these algorithms as well as a better understanding of their pros and cons to be able to cater to each dataset based on their characteristics.
    \end{abstract}

    \section{Introduction}
    \label{sec:introduction}

    This report is divided into three large sections corresponding to the first three tasks provided by the lecturer.
    We will explore and present our findings while putting the proposed algorithms into practice.

    Task 1 proposes utilizing the A-Priori algorithm in a Hadoop MapReduce program to discover groups of customers shopping on the same date as well as interacting with Hadoop Distributes File System (HDFS) to store files.
    By applying these methods, we will be able to understand how to extract patterns from large datasets locally.

    The second task focuses on implementing the Park-Chen-Yu (PCY) algorithm using Object-Oriented Programming (OOP) principles and PySpark DataFrame to identify frequent item pairs and generate association rules from customer purchase data stored in Google Drive.
    The implementation, while generating association rules, also has to follow object-oriented programming principles inspired by PySpark's Frequent-Pattern Growth (FPGrowth) class.

    In the third task, we will implement and compare the MinHashLSH algorithm and an alternative of our choice - in this case, a manual method of calculating Jaccard distance.
    Both of these approaches should achieve the same goal of searching for similar pairs of dates where the Jaccard distance is above a predetermined threshold.
    After that, we will visualize their runtime with their threshold ranging from 0 to 1 with 0.1 increments to gauge their performance and outline some characteristics between both approaches.
    Through these implementations, we demonstrate practical applications of data mining techniques with a given dataset.
    With these findings, we highlight the trade-offs between various aspects across different algorithms within the given time and constraints.

    \section{First Task: A-Priori Algorithm for Frequent Customers}
    \label{sec:first-task}
    \input{sections/first-task}

    \section{Second Task: PCY Algorithm for Frequent Items}
    \label{sec:second-task}
    \input{sections/second-task}

    \section{Third Task: MinHashLSH for Similar Dates}
    \label{sec:third-task}
    \input{sections/third-task}

    \section{Contribution}
    \label{sec:contribution}

    The following table represents the contribution of each member, note that whichever member handles whichever task will also write the report for that task.

    \begin{table}[h]
        \centering
        \caption{Members Contributions}
        \setlength{\tabcolsep}{2pt} % Reduce column spacing
        \renewcommand{\arraystretch}{1} % Adjust row spacing
        \resizebox{240}{!}{ % Fit within column width
            \begin{tabular}{|l|c|c|c|}
                \hline
                \textbf{ID} & \textbf{Member} & \textbf{Contribution} & \textbf{Progress}\\
                \hline
                522H0036 & Luong Canh Phong & Task 1 and Handling Report & 100\%\\
                522H0092 & Cao Nguyen Thai Thuan & Overseer and Report Support & 100\%\\
                522H0075 & Tang Minh Thien An & Task 3 & 100\%\\
                522H0167 & Truong Tri Phong & Task 2 & 100\%\\
                \hline
            \end{tabular}
        }
        \label{tab:contributions}
    \end{table}

    \section{Self-evaluation}
    \label{sec:self-evaluation}

    The following table is our self-evaluation on our tasks:

    \begin{table}[h]
        \centering
        \caption{Self-evaluation}
        \setlength{\tabcolsep}{2pt} % Reduce column spacing
        \renewcommand{\arraystretch}{1} % Adjust row spacing
        \resizebox{240}{!}{ % Fit within column width
            \begin{tabular}{|l|c|c|c|}
                \hline
                \textbf{Task} & \textbf{Task Requirements} & \textbf{Completion Ratio}\\
                \hline
                Task 1 & A-Priori Algorithm for Frequent Customers & 100\%\\
                Task 2 & PCY Algorithm for Frequent Items & 95\%\\
                Task 3 & MinHashLSH for Similar Dates & 90\%\\
                Task 4 & Report & 100\%\\
                \hline
            \end{tabular}
        }
        \label{tab:self-evaluation}
    \end{table}

    \section{Conclusion}
    \label{sec:conclusion}
    We have gone through a variety of techniques and algorithms used in the world of data mining.
    For the first task, we have to find same-day customers and utilize the A-Priori algorithm to find frequent pairs of customers that shop on the same date and save the output of each pass in a dedicated folder.
    As we run though the code, the result after sorting is a reasonable ascending list of frequent customer pairs.
    For the second task, store the given dataset locally and identify baskets, as well as implementing the PCY algorithm to find frequent pairs along with generating metadata with predetermined constraints, the results for this task are two separate lists, one containing all frequent pairs, and the other is a list of association rules based on the user's given support threshold and confidence value.
    And finally, implement and compare between a traditional and an alternative MinHashLSH function to understand and have a greater insight into how the frequent pairs searching is done.
    We can see that with a slight modification and a different way of merging, it can result in a notably higher efficiency and better results.

    \begin{thebibliography}{00}
        \bibitem{b12} Tpoint Tech, ``Apriori Algorithm, ''\\\
        [Online]. Available: \href{https://www.tpointtech.com/apriori-algorithm}{https://www.tpointtech.com/apriori-algorithm}
        \bibitem{b6} Databricks, ``MapReduce, '' Databricks Glossary, 2025.\\\
        [Online]. Available: \href{https://www.databricks.com/glossary/mapreduce}{https://www.databricks.com/glossary/mapreduce}
        \bibitem{b1} J. S. Park and M. S. Chen, ``Using a hash table to eliminate candidates in a frequent itemset mining algorithm, '' \textit{IEEE Trans. Knowl. Data Eng.}, vol. 7, no. 3, pp. 464--472, 1995.
        \bibitem{b2} J. Han, J. Pei, and Y. Yin, ``Mining frequent patterns without candidate generation, '' \textit{ACM SIGMOD Rec.}, vol. 29, no. 2, pp. 1--12, 2000.
        \bibitem{b3} PySpark Documentation, ``PySpark API Documentation, '' 2025.\\\
        [Online]. Available: \url{https://spark.apache.org/docs/latest/api/python}
        \bibitem{b4} PySpark Documentation, ``pyspark.ml.feature.MinHashLSH, '' Apache Spark, 2025.\\\
        [Online]. Available: \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.MinHashLSH}{https://spark.apache.org/docs/latest/api/python/refer\-ence/api/pyspark.ml.feature.MinHashLSH}
        \bibitem{b5} Amazon Web Services, ``Jaccard similarity, '' AWS Neptune Analytics Documentation, 2024.\\\
        [Online]. Available: \href{https://docs.aws.amazon.com/neptune-analytics/latest/userguide/jaccard-similarity.html}{https://docs.aws.amazon.com/neptune-analytics/latest/userguide/jaccard-similarity.html}
    \end{thebibliography}
\end{document}